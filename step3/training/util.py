import os
import pickle
import numpy as np
from sklearn import model_selection, preprocessing
from sklearn.feature_extraction.text import TfidfVectorizer

DATA_SET_PATH = "../data/opcode/"
MALWARE_PATH = "malware/"
NORMAL_PATH = "normal/"
STOP_POINT = 100

def read_data(file_path, STOP_POINT, sequences, labels, file_type):
    files = [file for file in os.listdir(file_path) if file.endswith(".txt")]
    count = 0
    for file in files:
        with open(file_path + file, 'r') as f:
            lines = f.readlines()
            sequences.append(" ".join(lines))
            labels.append(file_type)
        count += 1
        if count == STOP_POINT:
            break

def read_data_set(DATA_SET_PATH, STOP_POINT):
    global MALWARE_PATH, NORMAL_PATH
    sequences = []
    labels = []
    read_data(DATA_SET_PATH+MALWARE_PATH, STOP_POINT, sequences, labels, 1)
    read_data(DATA_SET_PATH+NORMAL_PATH, STOP_POINT, sequences, labels, 0)
    train_x, valid_x, train_y, valid_y = model_selection.train_test_split(
        sequences, labels)
    print(len(train_x), len(valid_x), len(train_y), len(valid_y))

    encoder = preprocessing.LabelEncoder()
    train_y = encoder.fit_transform(train_y)
    valid_y = encoder.fit_transform(valid_y)

    tfidf_vect_ngram = TfidfVectorizer(
        analyzer='word', token_pattern=r'\w{1,}', ngram_range=(3, 3), max_features=1000)

    tfidf_vect_ngram.fit(sequences)
    train_x = tfidf_vect_ngram.transform(train_x)
    valid_x = tfidf_vect_ngram.transform(valid_x)

    return train_x, valid_x, train_y, valid_y

def load_x_data(PATH) :
    with open(PATH, 'rb') as f:
        tmp = pickle.load(f)
        tmp = tmp.toarray()
        tmp = np.expand_dims(tmp, axis=1)
        tmp = np.expand_dims(tmp, axis=1)
    return tmp

def load_y_data(PATH) :
    with open(PATH, 'rb') as f:
        tmp = pickle.load(f)
    return tmp

if __name__=='__main__':
    # load_data("train_x.pickle")
    # exit()
    train_x, valid_x, train_y, valid_y = read_data_set(DATA_SET_PATH, STOP_POINT)
    with open('train_x.pickle', 'wb') as f :
        pickle.dump(train_x, f)
    with open('valid_x.pickle', 'wb') as f :
        pickle.dump(valid_x, f)
    with open('train_y.pickle', 'wb') as f:
        pickle.dump(train_y, f)
    with open('valid_y.pickle', 'wb') as f:
        pickle.dump(valid_y, f)


